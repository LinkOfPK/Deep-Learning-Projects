{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2190eac7-9645-4f5d-a5f7-d733e1fa5400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[2., 2.],\n",
      "        [2., 2.]])\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]])\n",
      "tensor([[4., 4.],\n",
      "        [4., 4.]])\n",
      "tensor([[1.4142, 1.4142],\n",
      "        [1.4142, 1.4142]])\n"
     ]
    }
   ],
   "source": [
    "#tensor operations\n",
    "\n",
    "import torch\n",
    "\n",
    "ones =torch.zeros(2,2) +1\n",
    "twos =torch.ones(2,2) *2\n",
    "threes =(torch.ones(2,2) *7-1)/2\n",
    "fours =twos **2\n",
    "sqrt2s =twos **0.5\n",
    "\n",
    "print(ones)\n",
    "print(twos)\n",
    "print(threes)\n",
    "print(fours)\n",
    "print(sqrt2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcea24f3-508c-4267-9e2c-e185415c559f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.,  4.],\n",
      "        [ 8., 16.]])\n",
      "tensor([[5., 5.],\n",
      "        [5., 5.]])\n",
      "tensor([[12., 12.],\n",
      "        [12., 12.]])\n"
     ]
    }
   ],
   "source": [
    "powers2 =twos **torch.tensor([[1,2],[3,4]])\n",
    "print(powers2)\n",
    "\n",
    "fives =ones +fours\n",
    "print(fives)\n",
    "\n",
    "dozens =threes *fours\n",
    "print(dozens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d0ffcf2-42ae-40c5-a6b0-0360eb15a679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11, 22],\n",
      "        [13, 24]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2],\n",
    "                  [3, 4]])\n",
    "\n",
    "b = torch.tensor([10, 20])  # shape: (2,)\n",
    "print(a + b)  # 자동으로 [10, 20]이 각 행에 broadcast됨\n",
    "\n",
    "#이게 바로 PyTorch가 강력한 이유 중 하나죠! 복잡한 shape 간에도 자동으로 맞춰줍니다.\n",
    "#간단한 연산처럼 보여도, 이걸 잘 이해하고 있으면\n",
    "#📌 딥러닝 모델 만들 때 텐서 shape 오류를 줄이는 데 큰 도움이 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "966de360-9796-4401-b5c2-2323057996d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m a \u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      4\u001b[0m b \u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(a\u001b[38;5;241m*\u001b[39mb)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a =torch.rand(2,3)\n",
    "b =torch.rand(3,2)\n",
    "print(a*b)\n",
    "\n",
    "# RuntimeError: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension \n",
    "# 어느 한 차원도 맞지 않아서 브로드캐스트 할 수 없는 상황"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0893bc8-bbcf-42a2-801e-eec8d3408fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1161, 0.0903, 0.7056, 0.9102],\n",
      "        [0.7192, 0.9436, 0.3515, 0.3888]])\n",
      "tensor([[0.2323, 0.1807, 1.4112, 1.8204],\n",
      "        [1.4383, 1.8872, 0.7030, 0.7776]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "rand =torch.rand(2,4) #그 random이 맞다\n",
    "doubled =rand *(torch.ones(1,4) *2)\n",
    "print(rand)\n",
    "print(doubled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9ce0aa5-6dba-4af1-b6bd-b666dba6e386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a shape: torch.Size([4, 3, 2])\n",
      "b1 shape: torch.Size([3, 2])\n",
      "result shape: torch.Size([4, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# task1  텐서 브로드캐스트\n",
    "\n",
    "import torch\n",
    "\n",
    "a =torch.ones(4,3,2)\n",
    "print(\"a shape:\", a.shape)\n",
    "\n",
    "b1 =torch.rand(3,2)\n",
    "print(\"b1 shape:\", b1.shape)\n",
    "\n",
    "result1 = a +1\n",
    "print(\"result shape:\", result1.shape)\n",
    "\n",
    "#a에서 3차원 모양의(4,3,2) 토치를 만들었다\n",
    "#b1에서는 2차원 모양의(3,2) 토치를 만들었고\n",
    "#이를 브로드캐스트 했을 떄의 결과를 보라라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1555aab1-2288-447a-9945-397b9ffefbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common functions:\n",
      "tensor([[0.4118, 0.1860, 0.4834, 0.0798],\n",
      "        [0.6911, 0.9416, 0.0278, 0.8633]])\n",
      "tensor([[-0., -0., -0., 1.],\n",
      "        [1., -0., -0., -0.]])\n",
      "tensor([[-1., -1., -1.,  0.],\n",
      "        [ 0., -1., -1., -1.]])\n",
      "tensor([[-0.4118, -0.1860, -0.4834,  0.0798],\n",
      "        [ 0.5000, -0.5000, -0.0278, -0.5000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a =torch.rand(2,4) *2-1\n",
    "print('Common functions:')\n",
    "print(torch.abs(a)) #절댓값\n",
    "print(torch.ceil(a)) #올림값\n",
    "print(torch.floor(a)) #내림값\n",
    "print(torch.clamp(a, -0.5, 0.5)) #범위지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd392883-5fa0-47f9-8bce-8bceaf78b6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sine and arcsine:\n",
      "tensor([0.0000, 0.7854, 1.5708, 2.3562])\n",
      "tensor([0.0000, 0.7071, 1.0000, 0.7071])\n",
      "tensor([0.0000, 0.7854, 1.5708, 0.7854])\n"
     ]
    }
   ],
   "source": [
    "#삼각함수 텐서\n",
    "import torch\n",
    "import math\n",
    "\n",
    "angles =torch.tensor([0, math.pi/4, math.pi/2, 3*math.pi/4])\n",
    "sines =torch.sin(angles)\n",
    "inverses =torch.asin(sines)\n",
    "print('\\nSine and arcsine:')\n",
    "print(angles)\n",
    "print(sines)\n",
    "print(inverses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7abf3af7-db69-4b40-9749-82ed6456e6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bitwise XOR:\n",
      "tensor([3, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "#비트 연산자\n",
    "import torch\n",
    "\n",
    "print('\\nBitwise XOR:')\n",
    "a =torch.tensor([1,5,11])\n",
    "b =torch.tensor([2,7,10])\n",
    "print(torch.bitwise_xor(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b26d245-6942-45c3-a79a-ec174a9f5c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reduction ops:\n",
      "tensor(4.)\n",
      "4.0\n",
      "tensor(2.5000)\n",
      "tensor(1.2910)\n",
      "tensor(24.)\n",
      "tensor([1, 2])\n"
     ]
    }
   ],
   "source": [
    "#tensor Reductions\n",
    "import torch\n",
    "\n",
    "a =torch.tensor([[1.,2.],[3.,4.]])\n",
    "\n",
    "print('\\nReduction ops:')\n",
    "print(torch.max(a)) #최고값\n",
    "print(torch.max(a).item()) #벡터의 구성요소를 반환\n",
    "print(torch.mean(a)) #평균\n",
    "print(torch.std(a)) #평균 편차\n",
    "print(torch.prod(a)) #벡터 연산 (내정)\n",
    "print(torch.unique(torch.tensor([1,2,1,2,1,2,]))) #유일값 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f53f1711-9e12-43f2-83f5-3a24bdc57f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vectors & Matrices:\n",
      "tensor([ 0.,  0., -1.])\n",
      "\n",
      "무작위 생성 2x2 행렬 m1:\n",
      "tensor([[0.8632, 0.6381],\n",
      "        [0.4645, 0.7914]])\n",
      "\n",
      "행렬 곱 (matrix multiplication)→ m1 @ m2 와 동일한 결과\n",
      "SVD (Singular Value Decomposition): 특이값 분해\n",
      "tensor([[2.5897, 1.9142],\n",
      "        [1.3934, 2.3741]])\n",
      "\n",
      "\n",
      "torch.return_types.linalg_svd(\n",
      "U=tensor([[-0.7645, -0.6447],\n",
      "        [-0.6447,  0.7645]]),\n",
      "S=tensor([4.1529, 0.8382]),\n",
      "Vh=tensor([[-0.6930, -0.7209],\n",
      "        [-0.7209,  0.6930]]))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "v1 =torch.tensor([1.,0.,0.])\n",
    "v2 =torch.tensor([0.,1.,0.])\n",
    "m1 =torch.rand(2,2)\n",
    "m2 =torch.tensor([[3.,0.],[0.,3.]])\n",
    "\n",
    "print('\\nVectors & Matrices:')\n",
    "print(torch.linalg.cross(v2, v1))\n",
    "print('\\n무작위 생성 2x2 행렬 m1:')\n",
    "print(m1)\n",
    "\n",
    "print('\\n행렬 곱 (matrix multiplication)→ m1 @ m2 와 동일한 결과')\n",
    "m3 =torch.linalg.matmul(m1,m2)\n",
    "print('SVD (Singular Value Decomposition): 특이값 분해')\n",
    "print(m3)\n",
    "print('\\n')\n",
    "print(torch.linalg.svd(m3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59463127-b6f2-4583-99b1-7c2caff95d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1., 561.],\n",
      "        [  1.,   1.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a=torch.ones(2,2)\n",
    "b =a;\n",
    "\n",
    "a[0][1] =561\n",
    "print(b)\n",
    "\n",
    "# 둘이 독립적이면 값 변화가 없어야 하는데 그렇지 않음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f07e863f-62d3-4408-a4be-70bf8904c1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True],\n",
      "        [True, True]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a =torch.ones(2,2)\n",
    "b =a.clone()\n",
    "\n",
    "assert b is not a\n",
    "print(torch.eq(a,b))\n",
    "\n",
    "a[0][1] =561\n",
    "print(b)\n",
    "\n",
    "# b를 a의 클론으로 선언하면 서로 공간을 분할해서 사용한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4e32b58-9c47-4f7e-a9d8-c4dd14e40463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2404, 0.5564],\n",
      "        [0.3426, 0.4722]], requires_grad=True)\n",
      "tensor([[0.2404, 0.5564],\n",
      "        [0.3426, 0.4722]], grad_fn=<CloneBackward0>)\n",
      "tensor([[0.2404, 0.5564],\n",
      "        [0.3426, 0.4722]])\n",
      "tensor([[0.2404, 0.5564],\n",
      "        [0.3426, 0.4722]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# autograd 자동으로 기울기 계산을 할 것인지를 정하는 함수\n",
    "import torch\n",
    "\n",
    "a =torch.rand(2, 2, requires_grad =True)\n",
    "print(a)\n",
    "b =a.clone()\n",
    "print(b)\n",
    "\n",
    "c =a.detach().clone()\n",
    "print(c)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21ea2d3f-8574-4861-be2f-841d71b1d8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry, CPU only.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# cpu gpu 연산 가능 여부 확인\n",
    "if torch.cuda.is_available():\n",
    "    print('we have a CUDA accelerator!')\n",
    "else:\n",
    "    print('Sorry, CPU only.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5eff4941-153b-475c-935c-17c808f52093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry, CPU only.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    gpu_rand =torch.rand(2, 2, device =torch.cuda.current_device())\n",
    "    print(gpu_rand)\n",
    "else:\n",
    "    print('Sorry, CPU only.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00283075-2c64-4ea0-aa35-9b5f46570ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "tensor([[0.9682, 0.2638],\n",
      "        [0.8738, 0.9058]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device =torch.cuda.current_device() if torch.cuda.is_available() else torch.device('cpu')\n",
    "print('Device: {}'.format(device))\n",
    "\n",
    "x =torch.rand(2, 2, device =device)\n",
    "print(x)\n",
    "# 셀 수행 후 device 지정해서 호출하는 모습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a451968a-46a6-4c51-9b12-37434bcdde5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device =torch.cuda.current_device() if torch.cuda.is_available() else torch.device('cpu')\n",
    "print('Device: {}'.format(device))\n",
    "\n",
    "x =torch.rand(2,2)\n",
    "y =torch.rand(2, 2, device =device)\n",
    "z = x+y\n",
    "# 원래 y는 gpu를 할당해서 디바이스 다름 오류가 발생해야 하는데\n",
    "# 현재 환경에서는 내장 그래픽이기 떄문에 only cpu처리 되는 문제 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cfd8b733-7f83-4601-b303-dc47c8f788cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 226, 226])\n",
      "torch.Size([1, 3, 226, 226])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a =torch.rand(3, 226, 226)\n",
    "b =a.unsqueeze(0)\n",
    "print(a.shape)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7498ee75-d4ed-4a3a-b202-d7596ae66279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[0.9562]]]]])\n",
      "tensor(0.9562)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a =torch.rand(1, 1, 1, 1, 1)\n",
    "print(a)\n",
    "b =torch.squeeze(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8dfdc656-ec9a-4709-8543-7aedf8391a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "tensor([[0.1652, 0.0049, 0.8813, 0.5598, 0.1275, 0.2925, 0.4314, 0.6078, 0.8669,\n",
      "         0.0888, 0.6354, 0.9785, 0.2789, 0.8630, 0.0492, 0.0157, 0.5419, 0.3595,\n",
      "         0.3839, 0.9703]])\n",
      "\n",
      "\n",
      "torch.Size([20])\n",
      "tensor([0.1652, 0.0049, 0.8813, 0.5598, 0.1275, 0.2925, 0.4314, 0.6078, 0.8669,\n",
      "        0.0888, 0.6354, 0.9785, 0.2789, 0.8630, 0.0492, 0.0157, 0.5419, 0.3595,\n",
      "        0.3839, 0.9703])\n",
      "\n",
      "\n",
      "torch.Size([2, 2])\n",
      "tensor([[0.3604, 0.8689],\n",
      "        [0.1536, 0.8432]])\n",
      "\n",
      "\n",
      "torch.Size([2, 2])\n",
      "tensor([[0.3604, 0.8689],\n",
      "        [0.1536, 0.8432]])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a =torch.rand(1, 20) #대충 랜덤값 삽입 \n",
    "print(a.shape)\n",
    "print(a)\n",
    "print('\\n')\n",
    "b =a.squeeze(0)\n",
    "print(b.shape)\n",
    "print(b)\n",
    "print('\\n')\n",
    "\n",
    "c =torch.rand(2,2)\n",
    "print(c.shape)\n",
    "print(c)\n",
    "print('\\n')\n",
    "d =c.squeeze(0)\n",
    "print(d.shape)\n",
    "print(d)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "05f49f75-0c8a-4f6e-bb7a-4d74eb83ab66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 20, 20]) \n",
      "\n",
      "torch.Size([2400]) \n",
      "\n",
      "torch.Size([2400]) \n",
      "\n",
      "torch.Size([10, 10, 24])\n"
     ]
    }
   ],
   "source": [
    "#각 3차원 텐서를 1차원 또는 다른 형태로 reshape 하는 시시\n",
    "import torch\n",
    "output3d =torch.rand(6, 20, 20)\n",
    "print(output3d.shape, '\\n')\n",
    "# 3차원 텐서, 총 요소수 6*20*20=2400\n",
    "\n",
    "input1d =output3d.reshape(6*20*20)\n",
    "print(input1d.shape,'\\n\n",
    "# 3차원에서 1차원으로 평탄화 하는 작업, flatten\n",
    "# 총 요소수는 그대로 2400, torch.size([2400])\n",
    "\n",
    "print(torch.reshape(output3d, (6*20*20,)).shape, '\\n')\n",
    "# torch.reshape =직접 호출\n",
    "# 2번과 같은 1차원 flatten, 다만 reshpe()함수 형태로 직접 호출한 것\n",
    "\n",
    "others =output3d.reshape(10, 10, 24)\n",
    "print(others.shape)\n",
    "# 다시 1차원 텐서를 3차원 텐서로 변환, shape만 바꾼 것\n",
    "# 엔리멘탈 수는 여전히 동일하기 때문에 reshape 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dece3dcb-09bb-43af-8720-6d9f98ca5218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6783, 0.1770, 0.8543],\n",
      "        [0.3749, 0.1270, 0.3657],\n",
      "        [0.5147, 0.9510, 0.9631],\n",
      "        [0.2961, 0.3283, 0.3875]])\n",
      "tensor([[[0.6783, 0.1770, 0.8543],\n",
      "         [0.3749, 0.1270, 0.3657]],\n",
      "\n",
      "        [[0.5147, 0.9510, 0.9631],\n",
      "         [0.2961, 0.3283, 0.3875]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a =torch.rand(4,3)\n",
    "print(a)\n",
    "\n",
    "b =a.reshape(2, 2, 3)\n",
    "print(b)\n",
    "# 차원을 변형해도 엔리멘탈의 수는 유지되기 때문에 문제가 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6ad19f10-24dd-424f-8261-600224a6f449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8223, 0.4705, 0.6499, 0.0184, 0.6371, 0.3851, 0.7706, 0.1062, 0.6523,\n",
      "        0.5119, 0.0719, 0.0301])\n",
      "tensor([[0.8223, 0.4705, 0.6499, 0.0184],\n",
      "        [0.6371, 0.3851, 0.7706, 0.1062],\n",
      "        [0.6523, 0.5119, 0.0719, 0.0301]])\n"
     ]
    }
   ],
   "source": [
    "# tesk3\n",
    "import torch\n",
    "one_dimension_tensor =torch.rand(12)\n",
    "print(one_dimension_tensor)\n",
    "\n",
    "two_dimensions_tensor =one_dimension_tensor.reshape(3,4)\n",
    "print(two_dimensions_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "17b457a3-50c7-4dbb-ad8e-3390bd1c57f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9488, 0.5872, 0.9342, 0.0548, 0.7080, 0.8568, 0.6871, 0.9450, 0.3052,\n",
      "        0.8218, 0.9451, 0.8008, 0.6996, 0.5286, 0.3822, 0.3425, 0.8062, 0.9877,\n",
      "        0.6539, 0.1713, 0.2870, 0.6972, 0.8661, 0.4157, 0.0602, 0.3977, 0.0255,\n",
      "        0.3643, 0.5295, 0.1337, 0.3315, 0.4045, 0.4187, 0.6262, 0.9859, 0.2841,\n",
      "        0.6399, 0.3204, 0.6298, 0.0498, 0.5163, 0.4922, 0.9409, 0.9157, 0.0949,\n",
      "        0.3593, 0.1447, 0.0626, 0.8547, 0.4962, 0.8497, 0.6018, 0.8896, 0.5371,\n",
      "        0.1843, 0.4631, 0.4911, 0.9543, 0.4905, 0.8238, 0.9021, 0.9507, 0.7047,\n",
      "        0.3045, 0.3246, 0.9126, 0.7942, 0.4479, 0.6893, 0.9693, 0.5878, 0.7806,\n",
      "        0.3324, 0.3724, 0.9377, 0.9510, 0.3438, 0.7124, 0.7276, 0.3796, 0.3067,\n",
      "        0.4611, 0.6175, 0.5735, 0.1521, 0.4199, 0.0791, 0.4747, 0.7965, 0.0144,\n",
      "        0.0856, 0.0530, 0.4999, 0.9893, 0.6823, 0.0184, 0.2236, 0.1060, 0.7991,\n",
      "        0.5502, 0.3544, 0.0104, 0.5069, 0.3910, 0.0882, 0.4952, 0.8230, 0.9312,\n",
      "        0.0024, 0.0123, 0.9407, 0.2618, 0.6983, 0.4208, 0.4805, 0.0654, 0.7378,\n",
      "        0.6126, 0.2670, 0.5312])\n",
      "tensor([[[[0.9488, 0.5872, 0.9342, 0.0548, 0.7080, 0.8568, 0.6871, 0.9450,\n",
      "           0.3052, 0.8218],\n",
      "          [0.9451, 0.8008, 0.6996, 0.5286, 0.3822, 0.3425, 0.8062, 0.9877,\n",
      "           0.6539, 0.1713],\n",
      "          [0.2870, 0.6972, 0.8661, 0.4157, 0.0602, 0.3977, 0.0255, 0.3643,\n",
      "           0.5295, 0.1337],\n",
      "          [0.3315, 0.4045, 0.4187, 0.6262, 0.9859, 0.2841, 0.6399, 0.3204,\n",
      "           0.6298, 0.0498]],\n",
      "\n",
      "         [[0.5163, 0.4922, 0.9409, 0.9157, 0.0949, 0.3593, 0.1447, 0.0626,\n",
      "           0.8547, 0.4962],\n",
      "          [0.8497, 0.6018, 0.8896, 0.5371, 0.1843, 0.4631, 0.4911, 0.9543,\n",
      "           0.4905, 0.8238],\n",
      "          [0.9021, 0.9507, 0.7047, 0.3045, 0.3246, 0.9126, 0.7942, 0.4479,\n",
      "           0.6893, 0.9693],\n",
      "          [0.5878, 0.7806, 0.3324, 0.3724, 0.9377, 0.9510, 0.3438, 0.7124,\n",
      "           0.7276, 0.3796]],\n",
      "\n",
      "         [[0.3067, 0.4611, 0.6175, 0.5735, 0.1521, 0.4199, 0.0791, 0.4747,\n",
      "           0.7965, 0.0144],\n",
      "          [0.0856, 0.0530, 0.4999, 0.9893, 0.6823, 0.0184, 0.2236, 0.1060,\n",
      "           0.7991, 0.5502],\n",
      "          [0.3544, 0.0104, 0.5069, 0.3910, 0.0882, 0.4952, 0.8230, 0.9312,\n",
      "           0.0024, 0.0123],\n",
      "          [0.9407, 0.2618, 0.6983, 0.4208, 0.4805, 0.0654, 0.7378, 0.6126,\n",
      "           0.2670, 0.5312]]]])\n"
     ]
    }
   ],
   "source": [
    "# task4\n",
    "import torch\n",
    "one_dimension_tensor =torch.rand(120)\n",
    "print(one_dimension_tensor)\n",
    "\n",
    "four_dimensions_tensor =one_dimension_tensor.reshape(1, 3, 4, 10)\n",
    "print(four_dimensions_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d4525fb-0821-427a-a002-d257032d3ba8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SingleLayerPerceptron.__init__() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m#training settings\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m model \u001b[38;5;241m=\u001b[39mSingleLayerPerceptron(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     29\u001b[0m criterion \u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mBCELoss()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     30\u001b[0m optimizer \u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:488\u001b[0m, in \u001b[0;36mModule.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    483\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.__init__() got an unexpected keyword argument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    484\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    485\u001b[0m     )\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_super_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(args):\n\u001b[1;32m--> 488\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    489\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.__init__() takes 1 positional argument but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(args)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m were\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m given\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    491\u001b[0m     )\n\u001b[0;32m    493\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;124;03mCalls super().__setattr__('a', a) instead of the typical self.a = a\u001b[39;00m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;124;03mto avoid Module.__setattr__ overhead. Module's __setattr__ has special\u001b[39;00m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;124;03mhandling for parameters, submodules, and buffers but simply calls into\u001b[39;00m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;124;03msuper().__setattr__ for all other attributes.\u001b[39;00m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: SingleLayerPerceptron.__init__() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "# perceptron\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device ='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)\n",
    "\n",
    "#data preparation\n",
    "x =torch.FloatTensor([[0,0],[0,1],[1,0],[1,1]]).to(device)\n",
    "y =torch.FloatTensor([[0],[1],[1],[0]]).to(device)\n",
    "\n",
    "#network architecture\n",
    "class SingleLayerPerceptron(nn.Module):\n",
    "    def _init_(self, input_size, output_size =1):\n",
    "        super(SingleLayerPerceptron, self)._init_()\n",
    "        self.layer =nn.Sequential(nn.Linear(input_size, output_size, bias=True), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        output =self.layer(x)\n",
    "        return output\n",
    "\n",
    "#training settings\n",
    "model =SingleLayerPerceptron(2,1).to(device)\n",
    "criterion =torch.nn.BCELoss().to(device)\n",
    "optimizer =torch.optim.SGD(model.parameters(), lr =1)\n",
    "n_epochs =10000\n",
    "tot_losses =list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8886372-a773-4f00-a80a-2595720b6686",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
